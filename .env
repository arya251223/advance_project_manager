# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Model Timeouts (in seconds)
MODEL_TIMEOUT=1200
MODEL_MAX_TIMEOUT=1800


# Project Settings
GENERATED_DIR=generated

# API Settings
API_HOST=0.0.0.0
API_PORT=8000

# Development Mode
DEBUG=true
CREWAI_TRACING_ENABLED=true
